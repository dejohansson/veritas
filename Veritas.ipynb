{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import cm\n",
    "import json\n",
    "from itertools import zip_longest, product\n",
    "import os\n",
    "from math import sqrt\n",
    "import holidays\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# instance_varibles\n",
    "# GLOBAL_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../veritas_data/parser_menus/menu.json\", \"r\") as f:\n",
    "    MENU = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ts_data(file_name, start_date=None):\n",
    "    print(\"Loading main columns...\")\n",
    "    df = pd.read_csv(file_name, usecols=[\"device_id\", \"date\", \"store_id\", \"class\", \"total_price\"], header=0)\n",
    "\n",
    "    print(\"Formatting main columns...\")\n",
    "    df[\"device_id\"], device_map = df[\"device_id\"].factorize()\n",
    "    df[\"store_id\"], store_map = df[\"store_id\"].factorize()\n",
    "    df[\"class\"], class_map = df[\"class\"].factorize()\n",
    "    df = df.astype(\"uint32\")\n",
    "\n",
    "    print(\"Loading products...\")\n",
    "    with open(file_name, \"r\") as f:\n",
    "        num_columns = len(f.readline().split(\",\"))\n",
    "    for cols in zip_longest(*(iter(range(5, num_columns)),) * 50):\n",
    "        cols = [c for c in cols if c is not None]\n",
    "        temp_df = pd.read_csv(file_name, usecols=list(cols), header=0, dtype=\"uint8\")\n",
    "        temp_df = temp_df.loc[:, (temp_df != 0).any(axis=0)]   # Remove \"zero\" columns\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "    wl = [col for col in df.columns if col not in ['device_id', 'store_id', 'class', \"date\"]]\n",
    "    df = df.drop(df[df[wl].eq(0).all(axis=1)].index)\n",
    "    df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "    if start_date is not None:\n",
    "            df.drop(df[df[\"date\"] < start_date].index, inplace=True)\n",
    "    df.set_index([\"store_id\", \"device_id\", \"date\"], inplace=True)\n",
    "    return df, device_map, store_map, class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_FILE = \"../veritas_data/post_parser_orders/device_time_series.csv\"\n",
    "TSF, DEVICE_MAP, STORE_MAP, CLASS_MAP = load_ts_data(TS_FILE, \"2020-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSF.drop(\"class\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_WL = [col for col in TSF.columns if col not in [\"device_id\", \"store_id\", \"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Returns the device_id, number of orders and the data frame of the device with the most orders\n",
    "def get_top_devices(device_id_list, ts_frame, n):\n",
    "    top_devices = []\n",
    "    for device_id in device_id_list:\n",
    "        df = ts_frame.loc[ts_frame[\"device_id\"] == device_id, [\"store_id\"]]\n",
    "        try:\n",
    "            store_id = df.values[0][0]\n",
    "        except:\n",
    "            continue\n",
    "        num_orders = len(df.index)\n",
    "        top_devices.append((device_id, num_orders, store_id))\n",
    "        top_devices = sorted(top_devices, key=lambda d: d[1], reverse=True)[:n]\n",
    "    return top_devices\n",
    "\n",
    "# Returns df without rows where col_name equals a value occuring less than threshold times\n",
    "def trim_low_occurance_values(df, col_name, threshold):\n",
    "    s = df[col_name].value_counts().ge(threshold)\n",
    "    return df[df[col_name].isin(s[s].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# \n",
    "def get_intervals(df, t_delta):\n",
    "    first_date = df.index.min()[2]\n",
    "    last_date = df.index.max()[2]\n",
    "    time_step = last_date-t_delta\n",
    "    intervals = []\n",
    "    while time_step > first_date:\n",
    "        start = time_step\n",
    "        end = time_step+t_delta\n",
    "        intervals.append((start, end))\n",
    "        time_step -= (t_delta*max(min(np.random.normal(0.75, 0.05), 1), 0.5))\n",
    "    intervals.append((first_date, first_date+t_delta))\n",
    "    return intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def reindex_by_date(df, start, end, freq, fill_value=0):\n",
    "    dates = pd.date_range(start=start, end=end, freq=freq)\n",
    "    index = list(set(df.index.droplevel(\"date\").tolist()))\n",
    "    index.sort()\n",
    "    dates = [(i, j, d) for i, j in index for d in dates]\n",
    "    df = df.reindex(dates).fillna(0)\n",
    "    return df\n",
    "\n",
    "def flatten_ts(df):\n",
    "    return df.values.flatten()\n",
    "\n",
    "# \n",
    "def format_ts(df, start, end, freq, whitelist, flatten=False, normalize=False, sales_percentage=False):\n",
    "    product_cols = [col for col in df.columns if \"product\" in col]\n",
    "    df.rename(columns={\"total_price\": \"average_price\"}, inplace=True)\n",
    "    agg_dict = {col_name:np.sum for col_name in df.columns}\n",
    "    agg_dict.update({\"average_price\":np.mean})\n",
    "    df = df.groupby([df.index.get_level_values(i) for i in [0,1]]+[pd.Grouper(freq=freq, level=-1)]).agg(agg_dict)\n",
    "    df = reindex_by_date(df, df.index.get_level_values(\"date\")[0], df.index.get_level_values(\"date\")[-1], freq)\n",
    "    if sales_percentage:\n",
    "        df[product_cols] = df[product_cols].div(df[product_cols].sum(axis=1), axis=0)\n",
    "    if normalize:\n",
    "        df -= df.min()\n",
    "        df /= df.max()\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    if flatten:\n",
    "        df.index.droplevel(\"store_id\")\n",
    "        device_index = df.index.get_level_values(\"device_id\").unique()\n",
    "        df = df.groupby(level=\"device_id\").apply(flatten_ts)\n",
    "        df = pd.DataFrame(np.stack(df), index=device_index)\n",
    "    return df\n",
    "\n",
    "def correlation_matrix(df, start, end, freq, whitelist, dist_func, normalize=False, sales_percentage=False):\n",
    "    start_time = time.time()\n",
    "    ids = df.index.get_level_values(\"device_id\").unique()\n",
    "    err_df = pd.DataFrame(index=ids, columns=ids)\n",
    "\n",
    "    print(\"Formatting devices...\")\n",
    "    df = format_ts(df, start, end, freq, whitelist, normalize=normalize, sales_percentage=sales_percentage, flatten=True)\n",
    "\n",
    "    print(\"Generating correlation matrix...\")\n",
    "    err_df = pd.DataFrame(squareform(pdist(df, metric=\"euclidean\")), columns=df.index, index=df.index)\n",
    "    print(\"Done!\", \"\\tElapsed time:\", str(datetime.timedelta(seconds=(time.time()-start_time))))\n",
    "    return err_df\n",
    "\n",
    "def distance_score(df):\n",
    "    df -= df.min().min()\n",
    "    df /= df.max().max()\n",
    "    #df = 1 - df\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram, cophenet\n",
    "\n",
    "def cophenet_test(df, interval, freq, metrics, methods, whitelist=[], verbose=False):\n",
    "    intervals = get_intervals(df, interval)\n",
    "    scores = []\n",
    "    for i, (start, end) in enumerate(intervals):\n",
    "        if verbose:\n",
    "            print(\"\\rInterval:\", str(i+1) + \"/\" + str(len(intervals)), end=\"\")\n",
    "        interval = df[(df.index.get_level_values(\"date\") > start) & (df.index.get_level_values(\"date\") <= end)]\n",
    "        n_devices = interval.index.get_level_values(\"device_id\").nunique()\n",
    "\n",
    "        if n_devices > 1:\n",
    "            interval = format_ts(interval, start, end, freq, whitelist, flatten=True, normalize=True)\n",
    "            for metric in metrics:\n",
    "                dist = pdist(interval, metric=metric)\n",
    "                for method in methods:\n",
    "                    if method != \"ward\" or metric == \"euclidean\":\n",
    "                        link = linkage(dist, method=method)\n",
    "                        score = cophenet(link, dist)[0]\n",
    "                        scores.append((metric, method, score))\n",
    "    return scores\n",
    "\n",
    "def cop_interval_test(df, intervals, freqs, metrics, methods, whitelist=[], verbose=False):\n",
    "    start_time = time.time()\n",
    "    scores = []\n",
    "    if verbose:\n",
    "        print(\"Running tests...\")\n",
    "    for i, (interval, freq) in enumerate(product(intervals, freqs)):\n",
    "        res = cophenet_test(df, interval, freq, metrics, methods, whitelist=whitelist)\n",
    "        scores += [(interval, freq) + tup for tup in res]\n",
    "        if verbose:\n",
    "            time_est = (len(intervals)*len(freqs)-(i+1)) * (datetime.timedelta(seconds=(time.time()-start_time)) / (i+1))\n",
    "            print(\"\\rTest:\", str(i+1) + \"/\" + str(len(intervals)*len(freqs)), \"\\tTime remaining (est):\", str(time_est), end=\"\")\n",
    "    if verbose:\n",
    "        print(\"\\nDone! Total time:\", str(datetime.timedelta(seconds=(time.time()-start_time))))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, path):\n",
    "    if not os.path.isfile(path):\n",
    "        df.to_csv(path)\n",
    "    else:\n",
    "        print(path, \"already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = \"frequency_test_2W_30min_to_10080min\"\n",
    "TEST_RES_PATH = \"./test_results/\" + TEST_NAME + \".csv\"\n",
    "TEST_INDEX = [\"interval\", \"frequency\", \"metric\", \"method\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "INTERVALS = [pd.Timedelta(n, unit=\"W\") for n in [2]]# + [pd.Timedelta(n, unit=\"D\") for n in [2,3,5]]\n",
    "FREQS = [str(n)+\"min\" for n in range(30, 10081, 30)]\n",
    "DIST_METRICS = [\"euclidean\"]\n",
    "LINK_METHODS = [\"average\"]\n",
    "\n",
    "TEST_RES = cop_interval_test(TSF, INTERVALS, FREQS, DIST_METRICS, LINK_METHODS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = pd.DataFrame(TEST_RES, columns=[\"interval\", \"frequency\", \"metric\", \"method\", \"cophenet_score\"])\n",
    "TEST_DF.set_index(TEST_INDEX, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(TEST_DF, TEST_RES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = pd.read_csv(TEST_RES_PATH)\n",
    "#TEST_DF = pd.read_csv(\"./test_results/\" + \"frequency_test_1to168\" + \".csv\")\n",
    "\n",
    "#TEST_DF = pd.concat([TEST_DF, pd.read_csv(\"./test_results/\" + \"frequency_test_1to168\" + \".csv\")])\n",
    "TEST_DF.set_index(TEST_INDEX, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF[\"mean_cophenetic_score\"] = TEST_DF.groupby(level=list(range(4)))[\"cophenet_score\"].mean()\n",
    "TEST_DF[\"median_cophenetic_score\"] = TEST_DF.groupby(level=list(range(4)))[\"cophenet_score\"].median()\n",
    "TEST_DF[\"max_cophenetic_score\"] = TEST_DF.groupby(level=list(range(4)))[\"cophenet_score\"].max()\n",
    "TEST_DF[\"min_cophenetic_score\"] = TEST_DF.groupby(level=list(range(4)))[\"cophenet_score\"].min()\n",
    "TEST_DF.drop([\"cophenet_score\"], axis=1, inplace=True)\n",
    "TEST_DF = TEST_DF.loc[~TEST_DF.index.duplicated(keep='first')]\n",
    "TEST_DF.index = TEST_DF.index.set_levels(TEST_DF.index.get_level_values(\"frequency\").str.replace(\"min\", \"\").astype(\"int32\"), level=\"frequency\")\n",
    "TEST_DF = TEST_DF.sort_values(by=[\"frequency\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "plt.scatter(TEST_DF.index.get_level_values(\"frequency\"), TEST_DF[\"mean_cophenetic_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,25))\n",
    "ax = sns.heatmap(TEST_DF.sort_values(by=[\"mean_cophenetic_score\"], ascending=False), cmap=sns.cm.rocket_r, annot=True, fmt=\".4g\") #.sort_values(by=[\"mean_cophenetic_score\"], ascending=False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.yaxis.label.set_size(16)\n",
    "ax.set_title(\"Hierarchical clustering comparison\", fontsize=24)\n",
    "ax.text(0.5, -0.05, \"Cophonetic Correlation Score (higher is better)\\nSample frequency: 1 hour,    Interval length: 1 week,    Number of intervals: 8\",\n",
    "        verticalalignment=\"bottom\", horizontalalignment=\"center\",\n",
    "        transform=ax.transAxes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIST_METRICS = [\"euclidean\", \"cityblock\", \"cosine\", \"correlation\"]\n",
    "LINK_METHODS = [\"ward\", \"complete\", \"average\", \"single\", \"weighted\", \"centroid\", \"median\"]\n",
    "INTERVAL = pd.Timedelta(1, unit=\"W\")\n",
    "FREQ = \"1H\"\n",
    "COPHENET_SCORES = cophenet_test(TSF, INTERVAL, FREQ, DIST_METRICS, LINK_METHODS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP_DF = pd.DataFrame(COPHENET_SCORES, columns=[\"metric\", \"method\", \"cophenet_score\"])\n",
    "COP_DF.set_index([\"metric\", \"method\"], inplace=True)\n",
    "COP_DF[\"mean_cophenetic_score\"] = COP_DF.groupby([\"metric\", \"method\"])[\"cophenet_score\"].mean()\n",
    "COP_DF[\"median_cophenetic_score\"] = COP_DF.groupby([\"metric\", \"method\"])[\"cophenet_score\"].median()\n",
    "COP_DF[\"max_cophenetic_score\"] = COP_DF.groupby([\"metric\", \"method\"])[\"cophenet_score\"].max()\n",
    "COP_DF[\"min_cophenetic_score\"] = COP_DF.groupby([\"metric\", \"method\"])[\"cophenet_score\"].min()\n",
    "COP_DF.drop([\"cophenet_score\"], axis=1, inplace=True)\n",
    "COP_DF = COP_DF.loc[~COP_DF.index.duplicated(keep='first')]\n",
    "\n",
    "plt.figure(figsize=(12,15), )\n",
    "ax = sns.heatmap(COP_DF.sort_values(by=[\"mean_cophenetic_score\"], ascending=False), cmap=sns.cm.rocket_r, annot=True, fmt=\".4g\")\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.yaxis.label.set_size(16)\n",
    "ax.set_title(\"Hierarchical clustering comparison\", fontsize=24)\n",
    "ax.text(0.5, -0.05, \"Cophonetic Correlation Score (higher is better)\\nSample frequency: 1 hour,    Interval length: 1 week,    Number of intervals: 8\",\n",
    "        verticalalignment=\"bottom\", horizontalalignment=\"center\",\n",
    "        transform=ax.transAxes, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram, cophenet\n",
    "n_stores = len(set(device_to_store))\n",
    "n_clusters = 15\n",
    "SAMPLE_FREQUENCY = \"1H0min\"\n",
    "\n",
    "INTERVALS = get_intervals(TSF, pd.Timedelta(1, unit=\"D\"), SAMPLE_FREQUENCY)\n",
    "SCORES = []\n",
    "for START, END in INTERVALS:\n",
    "    print(START, \"--\", END)\n",
    "    INTERVAL = TSF[(TSF.index.get_level_values(\"date\") > START) & (TSF.index.get_level_values(\"date\") <= END)]\n",
    "    N_DEVICES = INTERVAL.index.get_level_values(\"device_id\").nunique()\n",
    "\n",
    "    if N_DEVICES > 1:\n",
    "        DF = format_ts(INTERVAL, START, END, SAMPLE_FREQUENCY, COL_WL, flatten=True, normalize=True)\n",
    "        DIST = pdist(DF, metric=\"euclidean\")\n",
    "        LINK = linkage(DIST, method=\"average\")\n",
    "        BEST_SCORE = {\"silhouette\": {\"score\": -1, \"n_clusters\": 0},\n",
    "                    \"cophenet_c\": cophenet(LINK, DIST)[0],\n",
    "                    \"n_devices\": N_DEVICES}\n",
    "        for N_CLUST in range(2, len(DF)//2):\n",
    "            CLUST = fcluster(LINK, t=N_CLUST, criterion=\"maxclust\")\n",
    "            SIL_SCORE = silhouette_score(squareform(DIST), CLUST, metric=\"precomputed\")\n",
    "            if SIL_SCORE > BEST_SCORE[\"silhouette\"][\"score\"]:\n",
    "                BEST_SCORE[\"silhouette\"] = {\"score\":SIL_SCORE, \"n_clusters\":N_CLUST}\n",
    "        SCORES.append(BEST_SCORE)\n",
    "        print(BEST_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 10))\n",
    "plt.scatter(range(2, len(DF)), SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 10})\n",
    "plt.figure(figsize=(0.7*n_stores, 0.7*n_clusters))\n",
    "I = np.unique(np.array([device_to_store, clusters]).T, axis=0, return_counts=True)\n",
    "A = np.zeros((n_stores,n_clusters))\n",
    "A[I[0][:,0], I[0][:,1]] = I[1]\n",
    "A = A.T\n",
    "sns.heatmap(A/A.sum(axis=0), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 22})\n",
    "plt.figure(figsize=(35, 10))\n",
    "plt.scatter(device_to_store, clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(215,200))\n",
    "plt.rcParams.update({\"font.size\": 150})\n",
    "SLICE=1000\n",
    "ax = sns.heatmap(ERR.iloc[:SLICE, :SLICE].fillna(0), mask=ERR.iloc[:SLICE, :SLICE].isna())\n",
    "ax.xaxis.tick_top() # x axis on top\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.savefig(\"output.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ERR.fillna(0), mask=ERR.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ERR.fillna(0), mask=ERR.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([[1,1,1],[2,2,2],[3,3,3]])\n",
    "b = pd.DataFrame([[1,2,3],[3,2,1],[3,3,3]])\n",
    "print(a.values)\n",
    "print(a.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = get_top_devices(range(len(DEVICE_MAP)), trim_low_occurance_values(TSF, \"device_id\", 1000), 10)\n",
    "print(DEVICE_MAP[DEVICES[0][0]], DEVICES[0][0], DEVICES[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_cols(df, row_index, n_cols):\n",
    "    if len(df) == 0:\n",
    "        return []\n",
    "    row_frame = df.iloc[row_index].copy()\n",
    "    columns = []\n",
    "    for _ in range(n_cols):\n",
    "        if len(row_frame) == 0:\n",
    "            break\n",
    "        col_id = row_frame.idxmax()\n",
    "        columns.append(col_id)\n",
    "        row_frame = row_frame.drop([col_id])\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_dict(labels):\n",
    "    #labels = [col for col in df.columns if col not in [\"device_id\", \"date\", \"store_id\", \"class\", \"total_price\"]]\n",
    "    colors = [cm.rainbow(i) for i in np.linspace(0, 1, len(labels))]\n",
    "    c_dict = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        c_dict[label] = colors[i]\n",
    "    return c_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START_INDEX = 0\n",
    "N_COLS = 6\n",
    "COL_SET = set()\n",
    "for D in DEVICES:\n",
    "    DEVICE_FRAME = TSF.loc[TSF[\"device_id\"] == D[0], COL_WL].copy()\n",
    "    DEVICE_FRAME = DEVICE_FRAME.drop([\"total_price\"], axis=1)\n",
    "    DEVICE_FRAME = DEVICE_FRAME.resample(\"H\").sum().iloc[START_INDEX:]\n",
    "    DEVICE_FRAME = DEVICE_FRAME.cumsum()\n",
    "    for C in get_top_cols(DEVICE_FRAME, -1, N_COLS):\n",
    "        COL_SET.add(C)\n",
    "COLOR_DICT = get_color_dict(COL_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for D in DEVICES:\n",
    "    DEVICE_FRAME = TSF.loc[TSF[\"device_id\"] == D[0], column_whitelist].copy()\n",
    "    if len(DEVICE_FRAME) == 0:\n",
    "        continue\n",
    "    DEVICE_FRAME = DEVICE_FRAME.drop([\"total_price\"], axis=1)\n",
    "    DEVICE_FRAME = DEVICE_FRAME.resample(\"H\").sum().iloc[START_INDEX:]\n",
    "    DEVICE_FRAME = DEVICE_FRAME.cumsum()\n",
    "    COLS = get_top_cols(DEVICE_FRAME, -1, N_COLS)\n",
    "    fig = plt.figure()\n",
    "    DEVICE_FRAME.plot(kind='line',y=COLS, figsize=(16, 10), color=[COLOR_DICT.get(x, '#666666') for x in COLS], linewidth=3.0)\n",
    "    plt.legend(prop={'size': 18})\n",
    "    plt.figtext(.5,.9, \"Device \"+str(D[0])+\", Store \"+str(D[2]),fontsize=24)\n",
    "    #plt.show()\n",
    "    plt.savefig(\"C:/Users/user/Desktop/store_/\"+str(D[2]+\"/\"+\"device_\"+str(D[0])+\"_day.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_cols(df):\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    df[\"day_of_week\"] = df.index.dayofweek\n",
    "    df[\"day_of_month\"] = df.index.day\n",
    "    df[\"month\"] = df.index.month\n",
    "    holidays_swe = holidays.Sweden(include_sundays=False)[df.index[0]: df.index[-1]]\n",
    "    df[\"holiday\"] = [1 if d in holidays_swe else 0 for d in df.index.date]\n",
    "\n",
    "def remove_zero_sequence(df, col, min_length):\n",
    "    mask = col.groupby((col != col.shift()).cumsum()).transform('count').lt(min_length)\n",
    "    mask = ~(mask | col.gt(0))\n",
    "    df.drop(mask[mask].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_split(df, train_len=pd.Timedelta(4, unit='W'), forecast_len=pd.Timedelta(1, unit='W'), expanding_window=False):\n",
    "    start = df.index.values[0]\n",
    "    split = start + train_len\n",
    "    forecast_end = split + forecast_len\n",
    "    end = df.index.values[-1]\n",
    "    sets = []\n",
    "    while end > forecast_end:\n",
    "        sets.append((df[start:split].index, df[split:forecast_end].index))\n",
    "        if not expanding_window:\n",
    "            start += train_len + forecast_len\n",
    "        split += train_len + forecast_len\n",
    "        forecast_end += train_len + forecast_len\n",
    "    return sets\n",
    "\n",
    "DEVICE_FRAME = TSF.loc[TSF[\"device_id\"] == DEVICES[0][0], COL_WL].copy()\n",
    "len(get_test_train_split(DEVICE_FRAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "def train_and_predict_var(train_set, n_steps):\n",
    "    model = VAR(endog=train_set)\n",
    "    model_fit = model.fit(maxlags=2, trend=\"nc\")\n",
    "    print(model_fit.y)\n",
    "    return\n",
    "    prediction = model_fit.forecast(model_fit.y, steps=n_steps)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "\n",
    "def validate(predictions, true_val):\n",
    "    sum_meanAE = mean_absolute_error(predictions, true_val).sum()\n",
    "    sum_medianAE = median_absolute_error(predictions, true_val).sum()\n",
    "    return sum_meanAE, sum_medianAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_FRAME = TSF.loc[TSF[\"device_id\"] == DEVICES[0][0], COL_WL].copy()\n",
    "#DEVICE_FRAME[\"orders\"] = 1\n",
    "AGG_DICT = {col_name:np.sum for col_name in DEVICE_FRAME.columns}\n",
    "AGG_DICT.update({\"total_price\":np.mean})\n",
    "DEVICE_FRAME = DEVICE_FRAME.resample(\"H\").agg(AGG_DICT).fillna(0).cumsum()\n",
    "DEVICE_FRAME.rename(columns={'total_price': 'average_price'}, inplace=True)\n",
    "DEVICE_FRAME.drop([\"average_price\"], axis=1, inplace=True)\n",
    "#remove_zero_sequence(DEVICE_FRAME, DEVICE_FRAME.orders, 25)\n",
    "#add_time_cols(DEVICE_FRAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_train = get_test_train_split(DEVICE_FRAME)\n",
    "pred = train_and_predict_var(DEVICE_FRAME.loc[test_train[0][0]], len(test_train[0][1]))\n",
    "validate(pred, DEVICE_FRAME.loc[test_train[0][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUM_TRUE = DEVICE_FRAME.loc[test_train[0][1]]#DEVICE_FRAME.loc[test_train[0][0]].append(DEVICE_FRAME.loc[test_train[0][1]])\n",
    "PRED = pd.DataFrame(index=SUM_TRUE.index,columns=SUM_TRUE.columns)\n",
    "for j in range(0,len(DEVICE_FRAME.loc[test_train[0][1]].columns)):\n",
    "    for i in range(0, len(pred)):\n",
    "       PRED.iloc[i][j] = pred[i][j]\n",
    "SUM_VAR = PRED\n",
    "COLS = get_top_cols(SUM_TRUE, -1, 5)\n",
    "COLOR_DICT = get_color_dict(COLS)\n",
    "_, ax = plt.subplots()\n",
    "SUM_TRUE.plot(ax=ax, kind='line',y=COLS, figsize=(20, 14), color=[COLOR_DICT.get(x, '#FFFFFF') for x in COLS], linewidth=3.0)\n",
    "SUM_VAR.plot(linestyle='dashed', ax=ax, kind='line',y=COLS, figsize=(20, 14), color=[COLOR_DICT.get(x, '#FFFFFF') for x in COLS], linewidth=3.0)\n",
    "plt.legend(prop={'size': 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in get_test_train_split(DEVICE_FRAME, pd.Timedelta(4, unit='W'), pd.Timedelta(1, unit='W')):\n",
    "    train = DEVICE_FRAME.loc[train]\n",
    "    test = DEVICE_FRAME.loc[test]#-train.iloc[-1]\n",
    "    pred = train_and_predict_var(train, len(test))\n",
    "    #validate(pred, test)\n",
    "\n",
    "    SUM_TRUE = test#DEVICE_FRAME.loc[test_train[0][0]].append(DEVICE_FRAME.loc[test_train[0][1]])\n",
    "    PRED = pd.DataFrame(index=test.index,columns=test.columns)\n",
    "    for j in range(0,len(test.columns)):\n",
    "        for i in range(0, len(pred)):\n",
    "            PRED.iloc[i][j] = pred[i][j]\n",
    "    SUM_VAR = PRED#-train.iloc[-1]\n",
    "    COLS = get_top_cols(SUM_TRUE, -1, 5)\n",
    "    COLOR_DICT = get_color_dict(COLS)\n",
    "    _, ax = plt.subplots()\n",
    "    train.append(SUM_TRUE).plot(ax=ax, kind='line',y=COLS, figsize=(20, 14), color=[COLOR_DICT.get(x, '#FFFFFF') for x in COLS], linewidth=3.0)\n",
    "    SUM_VAR.plot(linestyle='dashed', ax=ax, kind='line',y=COLS, figsize=(20, 14), color=[COLOR_DICT.get(x, '#FFFFFF') for x in COLS], linewidth=3.0)\n",
    "    plt.legend(prop={'size': 18})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.scatter(DEVICE_FRAME.index, DEVICE_FRAME[\"orders\"].cumsum())\n",
    "plt.figure(figsize=(20,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_PERCENT = 0.8\n",
    "TRAIN_SIZE = -336#int(len(DEVICE_FRAME)*TRAIN_PERCENT)\n",
    "TRAIN_Y = DEVICE_FRAME[:TRAIN_SIZE]\n",
    "TRAIN_Y = TRAIN_Y.loc[:, (TRAIN_Y != TRAIN_Y.iloc[0]).any()]\n",
    "VAL_Y = DEVICE_FRAME[TRAIN_Y.columns][TRAIN_SIZE:]\n",
    "#TRAIN_X = DEVICE_FRAME[\"day\"]\n",
    "#VAL_X = DEVICE_FRAME[\"day\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#creating the train and validation set\n",
    "train = TRAIN_Y\n",
    "valid = VAL_Y\n",
    "naive_pred = DEVICE_FRAME[TRAIN_SIZE-1:-1]\n",
    "\n",
    "#fit the model\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "model = VAR(endog=train)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# make prediction on validation\n",
    "prediction = model_fit.forecast(model_fit.y, steps=len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting predictions to dataframe\n",
    "pred = pd.DataFrame(index=valid.index,columns=VAL_Y.columns)\n",
    "for j in range(0,len(VAL_Y.columns)):\n",
    "    for i in range(0, len(prediction)):\n",
    "       pred.iloc[i][j] = prediction[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "source": [
    "#check rmse\n",
    "print(\"MAE VAR, MAE Naive, Min Val, Max Val\")\n",
    "MIN = valid.min()\n",
    "MAX = valid.max()\n",
    "SUM_MAE = 0\n",
    "for i in pred.columns:\n",
    "    SUM_MAE += mean_absolute_error(pred[i], valid[i])\n",
    "    print('MAE value for', str(i)+':\\t', mean_absolute_error(pred[i], valid[i]), \"\\t\", mean_absolute_error(naive_pred[i], valid[i]), \"\\t\", MIN[i], \"\\t\", MAX[i])\n",
    "print(\"AVG MAE:\", (SUM_MAE/len(VAL_Y.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#converting predictions to dataframe\n",
    "pred = pd.DataFrame(index=valid.index,columns=DEVICE_FRAME.columns)\n",
    "for j in range(0,len(DEVICE_FRAME.columns)):\n",
    "    for i in range(0, len(prediction)):\n",
    "       pred.iloc[i][j] = prediction[i][j]\n",
    "\n",
    "#check rmse\n",
    "print(\"RMSE for VAR predictions and Naive Predictions\")\n",
    "for i in DEVICE_FRAME.columns:\n",
    "    print('rmse value for', i, 'is : ', sqrt(mean_squared_error(pred[i], valid[i])), \"\\t\", sqrt(mean_squared_error(naive_pred[i], valid[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "DEVICE_FRAME = sc.fit_transform(DEVICE_FRAME)\n",
    "DEVICE_FRAME.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}